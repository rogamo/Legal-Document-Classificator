{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfbb37d",
   "metadata": {},
   "source": [
    "# Optuna Study â€“ Biâ€‘LSTM Hyperâ€‘Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna, os, tensorflow as tf, numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(MAX_VOCAB=25_000, MAX_LEN=120):\n",
    "    df = load_dataset(\"liar\", split=\"train\").to_pandas()[[\"statement\",\"label\"]]\n",
    "    df.columns = [\"text\",\"target\"]\n",
    "    df.target = df.target.apply(lambda x: 0 if x in [0,1,2] else 1)\n",
    "    tok = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<UNK>\")\n",
    "    tok.fit_on_texts(df.text)\n",
    "    X = pad_sequences(tok.texts_to_sequences(df.text), maxlen=MAX_LEN, padding=\"post\")\n",
    "    y = df.target.values\n",
    "    return tok, *train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31107311",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok, X_tr, X_te, y_tr, y_te = get_data()\n",
    "\n",
    "def objective(trial):\n",
    "    emb_dim    = trial.suggest_categorical(\"emb_dim\",[64,128,256])\n",
    "    lstm_units = trial.suggest_int(\"lstm_units\",32,128,step=32)\n",
    "    dropout    = trial.suggest_float(\"dropout\",0.1,0.5,step=0.1)\n",
    "    lr         = trial.suggest_float(\"lr\",1e-4,5e-3,log=True)\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(len(tok.word_index)+1, emb_dim, mask_zero=True),\n",
    "        Bidirectional(LSTM(lstm_units)),\n",
    "        Dropout(dropout),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr), metrics=[\"accuracy\"])\n",
    "    hist = model.fit(X_tr, y_tr, epochs=3, batch_size=128, validation_split=0.2, verbose=0)\n",
    "    val_acc = max(hist.history[\"val_accuracy\"])\n",
    "    tf.keras.backend.clear_session()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "study.best_params, study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_params\n",
    "emb_dim, lstm_units, dropout, lr = best[\"emb_dim\"],best[\"lstm_units\"],best[\"dropout\"],best[\"lr\"]\n",
    "tok_full, X_tr, X_te, y_tr, y_te = get_data()\n",
    "model = Sequential([\n",
    "    Embedding(len(tok_full.word_index)+1, emb_dim, mask_zero=True),\n",
    "    Bidirectional(LSTM(lstm_units)),\n",
    "    Dropout(dropout),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr), metrics=[\"accuracy\"])\n",
    "model.fit(X_tr, y_tr, epochs=5, batch_size=128, validation_split=0.1, verbose=0)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/bi_lstm_fake_news.h5\")\n",
    "import pickle\n",
    "with open(\"models/tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tok_full, f)\n",
    "print(\"ðŸš€ Saved tuned model to models/bi_lstm_fake_news.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}