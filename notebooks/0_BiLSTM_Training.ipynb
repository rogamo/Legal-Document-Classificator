{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631aa69d",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM – Fake‑News Detection\n",
    "Trains on the LIAR dataset (Hugging Face) and saves `models/bi_lstm_fake_news.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd07899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB = 25_000\n",
    "MAX_LEN   = 120\n",
    "EMB_DIM   = 128\n",
    "LSTM_UNITS= 64\n",
    "DROPOUT   = 0.3\n",
    "BATCH     = 128\n",
    "EPOCHS    = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf91a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"liar\", split=\"train\")\n",
    "df = ds.to_pandas()[[\"statement\", \"label\"]]\n",
    "df.columns = [\"text\",\"target\"]\n",
    "df[\"target\"] = df[\"target\"].apply(lambda x: 0 if x in [0,1,2] else 1)\n",
    "\n",
    "tok = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<UNK>\")\n",
    "tok.fit_on_texts(df.text)\n",
    "X = pad_sequences(tok.texts_to_sequences(df.text), maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "y = df.target.values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print('Train/val shapes:', X_tr.shape, X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(MAX_VOCAB, EMB_DIM, mask_zero=True),\n",
    "    Bidirectional(LSTM(LSTM_UNITS)),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c57932",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_te, y_te, verbose=0)\n",
    "print(f\"Test accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/bi_lstm_fake_news.h5\")\n",
    "import pickle\n",
    "with open(\"models/tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tok, f)\n",
    "print(\"✅  Model and tokenizer saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}